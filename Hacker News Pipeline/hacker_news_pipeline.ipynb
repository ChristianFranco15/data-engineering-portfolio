{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker News Pipeline\n",
    "## Introduction\n",
    "In this project, we will create a pipeline that returns JSON data of the top stories from [Hacker News](https://news.ycombinator.com/) in 2014. Using this pipeline, we will then run a sequence of basic natural language processing tasks. Our goal is to find the top 100 keywords of Hacker News posts in 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Class\n",
    "Here we will create a `Pipeline` class that uses multiple dependencies to perform tasks on our data. We will first start by creating a `DAG` (Directed Acyclic Graph) class so we can use it to enhance our pipeline task scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import io\n",
    "import csv\n",
    "import string\n",
    "from collections import deque\n",
    "from stop_words import stop_words\n",
    "\n",
    "\n",
    "class DAG():\n",
    "    def __init__(self):\n",
    "        self.graph = {}\n",
    "\n",
    "    def in_degrees(self):\n",
    "        in_degrees = {}\n",
    "        for node in self.graph:\n",
    "            if node not in in_degrees:\n",
    "                in_degrees[node] = 0\n",
    "            for pointed in self.graph[node]:\n",
    "                if pointed not in in_degrees:\n",
    "                    in_degrees[pointed] = 0\n",
    "                in_degrees[pointed] += 1\n",
    "        return in_degrees\n",
    "\n",
    "    def sort(self):\n",
    "        in_degrees = self.in_degrees()\n",
    "        to_visit = deque()\n",
    "        for node in self.graph:\n",
    "            if in_degrees[node] == 0:\n",
    "                to_visit.append(node)\n",
    "\n",
    "        searched = []\n",
    "        while to_visit:\n",
    "            node = to_visit.popleft()\n",
    "            for pointer in self.graph[node]:\n",
    "                in_degrees[pointer] -= 1\n",
    "                if in_degrees[pointer] == 0:\n",
    "                    to_visit.append(pointer)\n",
    "            searched.append(node)\n",
    "        return searched\n",
    "\n",
    "    def add(self, node, to=None):\n",
    "        if node not in self.graph:\n",
    "            self.graph[node] = []\n",
    "        if to:\n",
    "            if to not in self.graph:\n",
    "                self.graph[to] = []\n",
    "            self.graph[node].append(to)\n",
    "\n",
    "        if len(self.sort()) != len(self.graph):\n",
    "            raise Exception\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self):\n",
    "        self.tasks = DAG()\n",
    "\n",
    "    def task(self, depends_on=None):\n",
    "        def inner(function):\n",
    "            self.tasks.add(function)\n",
    "            if depends_on:\n",
    "                self.tasks.add(depends_on, function)\n",
    "            return function\n",
    "        return inner\n",
    "\n",
    "    def run(self):\n",
    "        scheduled = self.tasks.sort()\n",
    "        completed = {}\n",
    "        for task in scheduled:\n",
    "            for node, values in self.tasks.graph.items():\n",
    "                if task in values:\n",
    "                    completed[task] = task(completed[node])\n",
    "            if task not in completed:\n",
    "                completed[task] = task()\n",
    "        return completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the JSON Data\n",
    "Now we will load a JSON file containing Hacker News stories from 2014 as a Python `dict` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task()\n",
    "def file_to_json():\n",
    "    with open('hn_stories_2014.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        stories = data['stories']\n",
    "    return stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the Stories\n",
    "Now that we have loaded the stories as a list of `dict` objects, we can start filtering them to get the most popular stories of the year. We want to make sure these stories are links (not `Ask HN` posts), have a good number of points, and have at least some comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=file_to_json)\n",
    "def filter_stories(stories):\n",
    "    def is_popular(story):\n",
    "        return story['points'] > 50 and story['num_comments'] > 1 and not story['title'].startswith('Ask HN')\n",
    "\n",
    "    return (\n",
    "        story for story in stories\n",
    "        if is_popular(story)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to CSV\n",
    "Now that we have our filtered stories, we want to write them to a CSV file so that we can have a consistent data format when running future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to write a file in CSV format\n",
    "def build_csv(lines, header=None, file=None):\n",
    "    if header:\n",
    "        lines = itertools.chain([header], lines)\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerows(lines)\n",
    "    file.seek(0)\n",
    "    return file\n",
    "\n",
    "# Write filtered stories into a CSV file\n",
    "@pipeline.task(depends_on=filter_stories)\n",
    "def json_to_csv(stories):\n",
    "    lines = []\n",
    "    for story in stories:\n",
    "        lines.append(\n",
    "            (story['objectID'], datetime.strptime(story['created_at'],\n",
    "             \"%Y-%m-%dT%H:%M:%SZ\"), story['url'], story['points'], story['title'])\n",
    "        )\n",
    "    return build_csv(lines, header=['objectID', 'created_at', 'url', 'points', 'title'], file=io.StringIO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Title Column\n",
    "Now we want to extract the titles of the stories so that we can run a word frequency task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=json_to_csv)\n",
    "def extract_titles(csv_file):\n",
    "    reader = csv.reader(csv_file)\n",
    "    header = next(reader)\n",
    "    idx = header.index('title')\n",
    "\n",
    "    return (line[idx] for line in reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Titles\n",
    "In order to create our word frequency model, we want to make sure the words are consistent throughout each title. For this, we will lower case the titles and remove any punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=extract_titles)\n",
    "def clean_title(titles):\n",
    "    for title in titles:\n",
    "        title = title.lower()\n",
    "        title = ''.join(c for c in title if c not in string.punctuation)\n",
    "        yield title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Word Frequency Dictionary\n",
    "Now we can create a word frequency dictionary that takes in words as keys and their frequencies as values. \n",
    "\n",
    "We also want to make sure this dictionary does not include any stop words, which are words that occur frequently (such as \"the\", \"or\", etc.) and are commonly rejected in keyword searches. For this, we already imported a module called `stop_words` which includes a tuple of the most commonly used stop words in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=clean_title)\n",
    "def build_keyword_dictionary(titles):\n",
    "    word_freq = {}\n",
    "    for title in titles:\n",
    "        for word in title.split(' '):\n",
    "            if word and word not in stop_words:\n",
    "                if word not in word_freq:\n",
    "                    word_freq[word] = 1\n",
    "                word_freq[word] += 1\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the Top Words\n",
    "Now that we have our dictionary, we are ready to sort it so that we can find the top words used in all of our filtered titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on=build_keyword_dictionary)\n",
    "def top_keywords(word_freq):\n",
    "    freq_tuple = [\n",
    "        (word, word_freq[word])\n",
    "        for word in sorted(word_freq, key=word_freq.get, reverse=True)\n",
    "    ]\n",
    "    return freq_tuple[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion - Running the Pipeline\n",
    "Finally, we can test our pipeline by running it to return the top keywords from Hacker News stories in 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new', 186)\n",
      "('google', 168)\n",
      "('bitcoin', 102)\n",
      "('open', 93)\n",
      "('programming', 91)\n",
      "('web', 89)\n",
      "('data', 86)\n",
      "('video', 80)\n",
      "('python', 76)\n",
      "('code', 73)\n",
      "('facebook', 72)\n",
      "('released', 72)\n",
      "('using', 71)\n",
      "('2013', 66)\n",
      "('javascript', 66)\n",
      "('free', 65)\n",
      "('source', 65)\n",
      "('game', 64)\n",
      "('internet', 63)\n",
      "('microsoft', 60)\n",
      "('c', 60)\n",
      "('linux', 59)\n",
      "('app', 58)\n",
      "('pdf', 56)\n",
      "('work', 55)\n",
      "('language', 55)\n",
      "('software', 53)\n",
      "('2014', 53)\n",
      "('startup', 52)\n",
      "('apple', 51)\n",
      "('use', 51)\n",
      "('make', 51)\n",
      "('time', 49)\n",
      "('yc', 49)\n",
      "('security', 49)\n",
      "('nsa', 46)\n",
      "('github', 46)\n",
      "('windows', 45)\n",
      "('world', 42)\n",
      "('way', 42)\n",
      "('like', 42)\n",
      "('1', 41)\n",
      "('project', 41)\n",
      "('computer', 41)\n",
      "('heartbleed', 41)\n",
      "('git', 38)\n",
      "('users', 38)\n",
      "('dont', 38)\n",
      "('design', 38)\n",
      "('ios', 38)\n",
      "('developer', 37)\n",
      "('os', 37)\n",
      "('twitter', 37)\n",
      "('ceo', 37)\n",
      "('vs', 37)\n",
      "('life', 37)\n",
      "('big', 36)\n",
      "('day', 36)\n",
      "('android', 35)\n",
      "('online', 35)\n",
      "('years', 34)\n",
      "('simple', 34)\n",
      "('court', 34)\n",
      "('guide', 33)\n",
      "('learning', 33)\n",
      "('mt', 33)\n",
      "('api', 33)\n",
      "('says', 33)\n",
      "('apps', 33)\n",
      "('browser', 33)\n",
      "('server', 32)\n",
      "('firefox', 32)\n",
      "('fast', 32)\n",
      "('gox', 32)\n",
      "('problem', 32)\n",
      "('mozilla', 32)\n",
      "('engine', 32)\n",
      "('site', 32)\n",
      "('introducing', 31)\n",
      "('amazon', 31)\n",
      "('year', 31)\n",
      "('support', 30)\n",
      "('stop', 30)\n",
      "('built', 30)\n",
      "('better', 30)\n",
      "('million', 30)\n",
      "('people', 30)\n",
      "('text', 30)\n",
      "('3', 29)\n",
      "('does', 29)\n",
      "('tech', 29)\n",
      "('development', 29)\n",
      "('billion', 28)\n",
      "('developers', 28)\n",
      "('just', 28)\n",
      "('library', 28)\n",
      "('did', 28)\n",
      "('website', 28)\n",
      "('money', 28)\n",
      "('inside', 28)\n"
     ]
    }
   ],
   "source": [
    "result = pipeline.run()\n",
    "for keyword in result[top_keywords]:\n",
    "    print(keyword)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
